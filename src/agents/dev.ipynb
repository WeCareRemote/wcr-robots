{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5297a4a1-744d-4c36-bd17-b842fe0fc45c",
   "metadata": {},
   "source": [
    "# Form to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497aef8b-3f6e-4278-92a1-7e5b3d043a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e7451-f5c2-4462-86d3-67a804f7cac6",
   "metadata": {},
   "source": [
    "## Loading icebreakers_extract.csv as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68c192e-d71d-49e4-b43d-e4b41e711e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>questions</th>\n",
       "      <th>advisor_id</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>user_skill_id</th>\n",
       "      <th>preview_media_url</th>\n",
       "      <th>icebreaker_type</th>\n",
       "      <th>allow_quantity</th>\n",
       "      <th>share_allowed_org</th>\n",
       "      <th>share_allowed_platform</th>\n",
       "      <th>description</th>\n",
       "      <th>locale</th>\n",
       "      <th>icebreaker_translations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"id\":92540555320,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"id\":81797796808,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"id\":38078152200,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"id\":35844159078,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Financial Recovery Aid Applications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"id\":10699678759,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  price  \\\n",
       "0  Return Journey Planning - Eligibility & Legal ...    NaN   \n",
       "1  Return Journey Planning - Eligibility & Legal ...    NaN   \n",
       "2  Return Journey Planning - Eligibility & Legal ...    NaN   \n",
       "3  Return Journey Planning - Eligibility & Legal ...    NaN   \n",
       "4                Financial Recovery Aid Applications    NaN   \n",
       "\n",
       "                                           questions  advisor_id  deleted_at  \\\n",
       "0  [{\"id\":92540555320,\"body\":{\"body\":\"What is you...           1         NaN   \n",
       "1  [{\"id\":81797796808,\"body\":{\"body\":\"What is you...           1         NaN   \n",
       "2  [{\"id\":38078152200,\"body\":{\"body\":\"What is you...           1         NaN   \n",
       "3  [{\"id\":35844159078,\"body\":{\"body\":\"What is you...           1         NaN   \n",
       "4  [{\"id\":10699678759,\"body\":{\"body\":\"What is you...           1         NaN   \n",
       "\n",
       "   user_skill_id  preview_media_url  icebreaker_type  allow_quantity  \\\n",
       "0              2                NaN                1               0   \n",
       "1              2                NaN                1               0   \n",
       "2              2                NaN                1               0   \n",
       "3              8                NaN                1               0   \n",
       "4             39                NaN                1               0   \n",
       "\n",
       "   share_allowed_org  share_allowed_platform  \\\n",
       "0                  0                       0   \n",
       "1                  0                       0   \n",
       "2                  0                       0   \n",
       "3                  0                       0   \n",
       "4                  0                       0   \n",
       "\n",
       "                                         description locale  \\\n",
       "0  This questionnaire helps NGO counselors assess...     en   \n",
       "1  This questionnaire helps NGO counselors assess...     en   \n",
       "2  This questionnaire helps NGO counselors assess...     en   \n",
       "3  This questionnaire helps NGO counselors assess...     en   \n",
       "4  This questionnaire helps NGO counselors assess...     en   \n",
       "\n",
       "   icebreaker_translations  \n",
       "0                        3  \n",
       "1                        3  \n",
       "2                        3  \n",
       "3                        3  \n",
       "4                        3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/icebreakers_extract.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4991e64-2a66-4d02-acc4-aa37fc3f0755",
   "metadata": {},
   "source": [
    "### Droping irrelevant columns¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2273ac-1c72-4fca-ae4d-983b5763aa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>questions</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>[{\"id\":92540555320,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>[{\"id\":81797796808,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>[{\"id\":38078152200,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Return Journey Planning - Eligibility &amp; Legal ...</td>\n",
       "      <td>[{\"id\":35844159078,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Financial Recovery Aid Applications</td>\n",
       "      <td>[{\"id\":10699678759,\"body\":{\"body\":\"What is you...</td>\n",
       "      <td>This questionnaire helps NGO counselors assess...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Return Journey Planning - Eligibility & Legal ...   \n",
       "1  Return Journey Planning - Eligibility & Legal ...   \n",
       "2  Return Journey Planning - Eligibility & Legal ...   \n",
       "3  Return Journey Planning - Eligibility & Legal ...   \n",
       "4                Financial Recovery Aid Applications   \n",
       "\n",
       "                                           questions  \\\n",
       "0  [{\"id\":92540555320,\"body\":{\"body\":\"What is you...   \n",
       "1  [{\"id\":81797796808,\"body\":{\"body\":\"What is you...   \n",
       "2  [{\"id\":38078152200,\"body\":{\"body\":\"What is you...   \n",
       "3  [{\"id\":35844159078,\"body\":{\"body\":\"What is you...   \n",
       "4  [{\"id\":10699678759,\"body\":{\"body\":\"What is you...   \n",
       "\n",
       "                                         description  \n",
       "0  This questionnaire helps NGO counselors assess...  \n",
       "1  This questionnaire helps NGO counselors assess...  \n",
       "2  This questionnaire helps NGO counselors assess...  \n",
       "3  This questionnaire helps NGO counselors assess...  \n",
       "4  This questionnaire helps NGO counselors assess...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = ['advisor_id', \n",
    "           'deleted_at', \n",
    "           'user_skill_id', \n",
    "           'preview_media_url', \n",
    "           'icebreaker_type', \n",
    "           'allow_quantity', \n",
    "           'share_allowed_org', \n",
    "           'share_allowed_platform', \n",
    "           'locale', \n",
    "           'icebreaker_translations',\n",
    "          'price']\n",
    "\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfd8b6-1066-4bbc-801f-391389a7ab62",
   "metadata": {},
   "source": [
    "#### for a comparison of row 0 vs 1 vs 2 vs 3, kindly see `protoype_data_analysis_&_agent_development.ipynb` -> *initial comparison of question dicts*\n",
    "\n",
    "Questions and answers are the same, ids etc can be d/f."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8545d-64ff-4463-83a3-e862055d85b1",
   "metadata": {},
   "source": [
    "#### Form - Return Journey Planning - Eligibility & Legal Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3220b001-977a-4f53-bc4d-09694b8f14db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "string_form = \"\"\n",
    "question_number = 0\n",
    "skip            = False\n",
    "for i in json.loads(df['questions'][0]):\n",
    "    question_number+=1\n",
    "    current_string  = i['body']['body']\n",
    "\n",
    "    if question_number>=18:\n",
    "        current_string  = re.sub(r'\\s*\\(PII\\)', '', current_string)\n",
    "        current_list    = re.split(r'[:|]', current_string)\n",
    "        current_list[0] = \"Q\" + str(question_number) + \": \" + current_list[0] + ' (PII) ' + '?'\n",
    "        skip            = True\n",
    "\n",
    "    if skip == False:\n",
    "        current_list    = re.split(r'[:|]', current_string)\n",
    "        current_list[0] = \"Q\" + str(question_number) + \": \" + current_list[0] + '?'\n",
    "    for i,j in enumerate(current_list):\n",
    "        if i!=0:\n",
    "            # removing the first white space\n",
    "            current_list[i] = current_list[i][1:]\n",
    "            current_list[i] = str(i) + '. ' + current_list[i]\n",
    "            \n",
    "        string_form = string_form + current_list[i] + '\\n'\n",
    "        # print(current_list[i])\n",
    "    string_form+='\\n\\n'\n",
    "    # print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7675df5c-18ce-4ffe-adf5-f0de911cd603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(string_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ec05988-fcc4-4947-bc3d-51bd008d56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to a text file\n",
    "# with open(\"return_journey_planning_eligibility_nd_legal_requirements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(string_form)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53c059-ffc5-49df-9aec-c8598c878163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6\n",
    "# Abmeldung in Germany means deregistering your address when you move out or leave the country.\n",
    "# You must inform the local office (Bürgeramt or Einwohnermeldeamt) that you no longer live at your German address.\n",
    "# Afterward, you get a deregistration certificate, which helps you cancel contracts, insurance, or services.\n",
    "# This should be done shortly before or within about two weeks after leaving your home in Germany.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc028d2-3555-4168-b776-f8d1f00d8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .txt file as a string\n",
    "with open(\"./data/return_journey_planning_eligibility_nd_legal_requirements.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    form_str = file.read()\n",
    "\n",
    "# # Now text_data contains the whole file as a string\n",
    "# print(text_data)  # Print first 500 characters to check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f5480-ee5c-406b-91ff-d0d4db73e6da",
   "metadata": {},
   "source": [
    "#### Form - 'Financial Recovery Aid Applications'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9313f219-11e9-4eb0-b5f5-294f20b3a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "\n",
    "# string_form = \"\"\n",
    "# question_number = 0\n",
    "# skip            = False\n",
    "# for i in json.loads(df['questions'][4]):\n",
    "#     question_number+=1\n",
    "#     current_string  = i['body']['body']\n",
    "\n",
    "#     if question_number>=23:\n",
    "#         current_string  = re.sub(r'\\s*\\(PII\\)', '', current_string)\n",
    "#         current_list    = re.split(r'[:|]', current_string)\n",
    "#         current_list[0] = \"Q\" + str(question_number) + \": \" + current_list[0] + ' (PII) ' + '?' + '\\n' + '1.'\n",
    "#         skip            = True\n",
    "\n",
    "#     if skip == False:\n",
    "#         current_list    = re.split(r'[:|]', current_string)\n",
    "#         current_list[0] = \"Q\" + str(question_number) + \": \" + current_list[0] + '?'\n",
    "#     for i,j in enumerate(current_list):\n",
    "#         if i!=0:\n",
    "#             # removing the first white space\n",
    "#             current_list[i] = current_list[i][1:]\n",
    "#             current_list[i] = str(i) + '. ' + current_list[i]\n",
    "            \n",
    "#         string_form = string_form + current_list[i] + '\\n'\n",
    "#         # print(current_list[i])\n",
    "#     string_form+='\\n\\n'\n",
    "#     # print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "56f72899-4c9c-4833-9cfb-76f3b739dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(string_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb838fba-3f38-42c8-9d71-b4fde53663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to a text file\n",
    "# with open(\"financial_recovery_aid_applications.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(string_form)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb0af4-7945-4996-8a77-5ea7279d8445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da040034-de16-4ce0-89c6-16fe3f9118a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---temporarily allowed all origins---\n"
     ]
    }
   ],
   "source": [
    "# 1) Make sure the .env from the repo root is loaded into the current process\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(\".env\", usecwd=True))  # searches upward from CWD\n",
    "\n",
    "import os\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found after loading .env\"\n",
    "\n",
    "# 2) Ensure the project 'src' is on sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # now 'src' is on path\n",
    "\n",
    "from core import settings\n",
    "# # --- Option A: import via the package (may import other agents too)\n",
    "# from agents.interrupt_agent import interrupt_agent\n",
    "from schema import (\n",
    "    ChatHistory,\n",
    "    ChatHistoryInput,\n",
    "    ChatMessage,\n",
    "    Feedback,\n",
    "    FeedbackResponse,\n",
    "    ServiceMetadata,\n",
    "    StreamInput,\n",
    "    UserInput,\n",
    ")\n",
    "\n",
    "from service.utils import (\n",
    "    convert_message_content_to_string,\n",
    "    langchain_to_chat_message,\n",
    "    remove_tool_calls,\n",
    ")\n",
    "\n",
    "# from agents.self_corrective_rag import self_corrective_rag\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5aadf-ea01-4827-b249-95297c1bfb10",
   "metadata": {},
   "source": [
    "# Agent Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f9e1f2-e3b8-44cd-b644-cc02a56adf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, convert_to_messages, BaseMessage, FunctionMessage, ChatMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import Optional, Literal, Annotated, List, Dict, Any, Iterable, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.types import StreamWriter\n",
    "from langfuse import Langfuse, get_client\n",
    "import json\n",
    "\n",
    "from schema import Ask_Ai_AgentState\n",
    "from core import get_model, settings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# # Access API keys and credentials\n",
    "# OPENAI_API_KEY    = os.environ[\"OPENAI_API_KEY\"]\n",
    "# GEMINI_API_KEY    = os.environ[\"GEMINI_API_KEY\"]\n",
    "# # TIMESCALE_DB_URI  = os.environ[\"TIMESCALE_DB_URI\"]\n",
    "# # MAIN_AGENT_DB_URI = os.environ[\"MAIN_AGENT_DB_URI\"]\n",
    "# # TAVILY_API_KEY    = os.environ[\"TAVILY_API_KEY\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------- Configuring LangFuse ---------------------------------------\n",
    "if settings.LANGFUSE_TRACING==True:\n",
    "    langfuse_public_key = settings.LANGFUSE_PUBLIC_KEY #os.environ[\"langfuse_public_key\"]\n",
    "    langfuse_secret_key = settings.LANGFUSE_SECRET_KEY #os.environ[\"langfuse_secret_key\"]\n",
    "    langfuse_host       = settings.LANGFUSE_HOST       #os.environ[\"langfuse_host\"]\n",
    "    \n",
    "    langfuse = Langfuse(\n",
    "      secret_key = langfuse_secret_key.get_secret_value(),\n",
    "      public_key = langfuse_public_key.get_secret_value(),\n",
    "      host       = langfuse_host\n",
    "    )\n",
    "    \n",
    "    langfuse_cl = get_client(public_key=langfuse_public_key.get_secret_value())\n",
    "\n",
    "# try:\n",
    "#     # pulling prompts from Langfuse server\n",
    "#     langfuse_ANSWER_USER_QUERY_SYSTEM_MESSAGE = langfuse_cl.get_prompt(\n",
    "#         name=\"ANSWER_USER_QUERY_SYSTEM_MESSAGE\",\n",
    "#         type=\"text\",\n",
    "#     ).get_langchain_prompt()\n",
    "\n",
    "#     langfuse_RELEVANCE_GRADER_SYSTEM_MESSAGE = langfuse_cl.get_prompt(\n",
    "#         name=\"RELEVANCE_GRADER_SYSTEM_MESSAGE\",\n",
    "#         type=\"chat\",\n",
    "#     ).get_langchain_prompt()\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"Unable to pull prompts from Langfuse server\")\n",
    "#     print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------- SCHEMAS ---------------------------------------\n",
    "\n",
    "class GradeRelevance(BaseModel):\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        description=(\n",
    "            \"Is the user's message relevant to Refugee_Bridge support for using the wcr.is website or completing its forms (including greetings while using the service)? 'yes' or 'no'.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# RELEVANCE_GRADER_SYSTEM_MESSAGE = \"\"\"\n",
    "# You are `ask ai`, an assistant for refugees using the wcr.is website. The site has multiple forms; users pick the one matching their current need and fill it out in another tab. While completing a form, they may ask about words, legal terms, or any confusing part. Your job is to guide them so they can finish the form correctly.\n",
    "\n",
    "# TASK: Decide if the user's message is relevant to Refugee_Bridge assistance. Return ONLY a binary score: 'yes' or 'no'.\n",
    "\n",
    "# Mark as 'yes' if the message concerns: using wcr.is; choosing/finding the right form; understanding or answering form questions (You do not have access to the form itself, so you must infer. If the message appears to come from a user filling out a form and asking about something within it, classify as 'yes'.); definitions of legal/immigration terms; document requirements; site navigation or technical issues; or general greetings/openers while using the service. Do NOT classify greetings as 'no'.\n",
    "\n",
    "# Mark as 'no' only if the message is clearly unrelated to refugee support or the wcr.is forms.\n",
    "# \"\"\"\n",
    "\n",
    "# RELEVANCE_GRADER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", RELEVANCE_GRADER_SYSTEM_MESSAGE),\n",
    "#     (\"human\",  \"The user's message:\\n{query}\")\n",
    "# ])\n",
    "\n",
    "try:\n",
    "    langfuse_RELEVANCE_GRADER_SYSTEM_MESSAGE = langfuse_cl.get_prompt(\n",
    "        name=\"RELEVANCE_GRADER_SYSTEM_MESSAGE\",\n",
    "        type=\"chat\"\n",
    "    )\n",
    "    \n",
    "    RELEVANCE_GRADER_PROMPT = ChatPromptTemplate(\n",
    "        langfuse_RELEVANCE_GRADER_SYSTEM_MESSAGE.get_langchain_prompt(),\n",
    "        metadata={\"langfuse_prompt\": langfuse_RELEVANCE_GRADER_SYSTEM_MESSAGE}  # exactly like that for linked generation\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Unable to pull prompts from Langfuse server: RELEVANCE_GRADER_SYSTEM_MESSAGE\")\n",
    "    print(e)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def get_cfg(config: RunnableConfig) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract the `configurable` dictionary from a RunnableConfig.\n",
    "\n",
    "    If no config is provided, returns an empty dictionary.\n",
    "\n",
    "    Args:\n",
    "        config: The runtime configuration object.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of configurable values (like user language or form string).\n",
    "    \"\"\"\n",
    "    return (config or {}).get(\"configurable\", {})  # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------- NODES ---------------------------------------\n",
    "\n",
    "def last_human_text(messages: List[BaseMessage]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Get the text of the most recent human message.\n",
    "\n",
    "    Looks through the list of messages in reverse order (latest first).\n",
    "    Returns the text content of the first HumanMessage found.\n",
    "    If no human message is present, returns None.\n",
    "    \"\"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            return msg.content\n",
    "    return None\n",
    "\n",
    "\n",
    "def trim_messages(messages: List[BaseMessage], max_messages: int = 8) -> List[BaseMessage]:\n",
    "    \"\"\"\n",
    "    Keep only the most recent messages.\n",
    "\n",
    "    Cuts the message history down to the last `max_messages` items.\n",
    "    This helps keep the context small and efficient when sending to the model.\n",
    "    \"\"\"\n",
    "    return messages[-max_messages:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _coerce_text(content) -> str:\n",
    "    \"\"\"Safely turn message.content into text.\"\"\"\n",
    "    if isinstance(content, str):\n",
    "        return content.strip()\n",
    "    try:\n",
    "        # Pretty-print dicts/lists; fallback to str for anything else\n",
    "        return json.dumps(content, ensure_ascii=False, indent=None)\n",
    "    except Exception:\n",
    "        return str(content).strip()\n",
    "\n",
    "\n",
    "def _role_of(msg: BaseMessage) -> str:\n",
    "    \"\"\"Map a message object to a simple role label.\"\"\"\n",
    "    # LangChain messages expose .type (e.g., 'human', 'ai', 'system', ...)\n",
    "    t = getattr(msg, \"type\", None)\n",
    "    if t:\n",
    "        return t\n",
    "    # Fallbacks for custom ChatMessage etc.\n",
    "    if isinstance(msg, ChatMessage) and hasattr(msg, \"role\"):\n",
    "        return msg.role\n",
    "    # Last resort: class name\n",
    "    return msg.__class__.__name__.lower()\n",
    "\n",
    "\n",
    "def chat_history_to_text(\n",
    "    messages: Iterable[BaseMessage],\n",
    "    *,\n",
    "    max_chars_per_message: int | None = None,\n",
    "    include_ids: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert a list of LangChain BaseMessage objects into a simple 'role: text' transcript.\n",
    "\n",
    "    Params\n",
    "    - messages: list/iterable of BaseMessage\n",
    "    - max_chars_per_message: truncate each message's text to this many characters (None = no truncation)\n",
    "    - include_ids: append message id in square brackets after the role (if present)\n",
    "\n",
    "    Returns\n",
    "    - A single string like:\n",
    "        human: Hi\n",
    "        ai: Hello!\n",
    "        system: ...\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for m in messages:\n",
    "        role = _role_of(m)\n",
    "        # Normalize a couple of common labels\n",
    "        role = {\"human\": \"human\", \"ai\": \"ai\", \"system\": \"system\", \"tool\": \"tool\", \"function\": \"function\"}.get(role, role)\n",
    "\n",
    "        text = _coerce_text(getattr(m, \"content\", \"\"))\n",
    "        if max_chars_per_message is not None and len(text) > max_chars_per_message:\n",
    "            text = text[: max_chars_per_message - 1] + \"…\"\n",
    "\n",
    "        suffix = f\" [{getattr(m, 'id', '')}]\" if include_ids and getattr(m, \"id\", None) else \"\"\n",
    "        # Collapse Windows newlines to \\n but otherwise leave content as-is\n",
    "        text = text.replace(\"\\r\\n\", \"\\n\").strip()\n",
    "\n",
    "        lines.append(f\"{role}:{suffix} {text}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "\n",
    "async def query_relevance(state: Ask_Ai_AgentState, config: RunnableConfig) -> Ask_Ai_AgentState:\n",
    "    \"\"\"\n",
    "    Prepare the user's last question for the relevance check.\n",
    "\n",
    "    Steps:\n",
    "    1. Take the conversation history from state.\n",
    "    2. Trim it to the most recent messages (default 8).\n",
    "    3. Extract the latest human message text.\n",
    "    4. Save that text into state as `user_question`.\n",
    "\n",
    "    Returns a partial Ask_Ai_AgentState with only the new `user_question` set.\n",
    "    \"\"\"\n",
    "    msgs = trim_messages(state.messages)\n",
    "    text = last_human_text(msgs) or \"\"\n",
    "    return {\"user_question\": text}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def query_relevance_router(state: Ask_Ai_AgentState, config: RunnableConfig) -> Literal[\"cant_help\", \"answer_user_query\"]:\n",
    "    \"\"\"\n",
    "    Decide whether the assistant should answer the user or decline.\n",
    "\n",
    "    Process:\n",
    "    1. Take the latest user question from state.\n",
    "    2. Send it to an LLM with the relevance grading prompt.\n",
    "    3. The model returns a binary score: \"yes\" (relevant) or \"no\" (not relevant).\n",
    "    4. If \"yes\", route to the \"answer_user_query\" node.\n",
    "       If \"no\", route to the \"cant_help\" node.\n",
    "\n",
    "    Returns:\n",
    "        A string literal: either \"answer_user_query\" or \"cant_help\".\n",
    "    \"\"\"\n",
    "    user_question = state.user_question or \"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # llm = ChatGoogleGenerativeAI(\n",
    "    #     model=\"gemini-2.0-flash-lite\",\n",
    "    #     api_key=GEMINI_API_KEY,\n",
    "    #     temperature=0,\n",
    "    #     max_output_tokens=100,\n",
    "    # )\n",
    "\n",
    "\n",
    "    llm    = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "    # print(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "\n",
    "    grader = (RELEVANCE_GRADER_PROMPT | llm.with_structured_output(GradeRelevance)).with_config(tags=[\"skip_stream\"])\n",
    "    relevance_grade: GradeRelevance = await grader.ainvoke(\n",
    "        {\n",
    "            \"query\":         user_question,\n",
    "            \"chat_history\":  chat_history_to_text(trim_messages(state.messages)[:-1]), \n",
    "            \n",
    "        }\n",
    "    )\n",
    "\n",
    "    score = (relevance_grade.binary_score or \"\").strip().lower()\n",
    "    return \"answer_user_query\" if score == \"yes\" else \"cant_help\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "async def cant_help(state: Ask_Ai_AgentState, config: RunnableConfig, writer: StreamWriter) -> Ask_Ai_AgentState:  # writer auto-injected\n",
    "    \"\"\"\n",
    "    Send a polite message when the assistant cannot help.\n",
    "\n",
    "    Behavior:\n",
    "    - Checks the user's chosen language from config (default: English).\n",
    "    - If the language is Russian or Ukrainian, replaces the default text\n",
    "      with a localized version.\n",
    "    - Streams the response word by word using the writer (so the user\n",
    "      sees it appear gradually).\n",
    "    - Returns the full AIMessage with the chosen \"can't help\" text.\n",
    "\n",
    "    Args:\n",
    "        state:  The current agent state.\n",
    "        config: Runtime configuration (contains user settings).\n",
    "        writer: Streaming callback, auto-injected by LangGraph.\n",
    "\n",
    "    Returns:\n",
    "        Ask_Ai_AgentState update with the assistant's \"can't help\" message.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg(config)\n",
    "    user_language = cfg.get(\"user_language\", \"english\")\n",
    "\n",
    "    # print(user_language)\n",
    "\n",
    "    if user_language.lower() == 'russian':\n",
    "        state.cant_help_text = 'Извините, я не могу вам помочь в этом вопросе.'\n",
    "    elif user_language.lower() == 'ukrainian':\n",
    "        state.cant_help_text = 'Вибачте, я не можу вам допомогти в цьому питанні.'\n",
    "    for word in state.cant_help_text.split():\n",
    "        writer(word + ' ')\n",
    "    return {\"messages\": [AIMessage(content=state.cant_help_text)]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ANSWER_USER_QUERY_SYSTEM_MESSAGE = \"\"\"\n",
    "# Your name is `ask ai`. You are a kind, patient assistant for refugees using the wcr.is website.\n",
    "\n",
    "# The site has multiple forms.\n",
    "# The user chooses the form that matches their current need.\n",
    "# They fill out the form in another tab, not in this chat.\n",
    "# While completing it, they may ask you about words, legal terms, or any confusing part.\n",
    "# Your job is to guide them so they can finish the form correctly.\n",
    "\n",
    "# How to respond:\n",
    "# - The user has selected <user_language> {user_language} </user_language> language. So your response should be in <user_language> {user_language} </user_language> language.\n",
    "# - Be very polite and supportive.\n",
    "# - Use short sentences.\n",
    "# - Use simple, everyday language.\n",
    "# - Explain step by step.\n",
    "# - Focus on the exact question the user is stuck on.\n",
    "# - Give short examples when helpful.\n",
    "# - If you need details, ask one clear question at a time.\n",
    "# - Adjust your tone and explanation style to fit the person you’re talking to.\n",
    "#     - If the person is not well-educated, avoid technical terms. Use simple words and short sentences.\n",
    "#     - If the person seems to be in trauma, respond with care, love, and support. Focus on uplifting their spirit.\n",
    "#     - Infer the person’s eloquence based on how their question is written. \n",
    "#         - If the question is unclear or sloppy: use simpler language, slow down, and give more (and more concrete) examples.\n",
    "#         - If the question is eloquent and precise: be succinct and get straight to the point, with minimal examples.\n",
    "\n",
    "# - Name of the form is given below. Always tell the user that you are currently helping with this form.\n",
    "\n",
    "# Current form:\n",
    "# <form>\n",
    "# {form_str}\n",
    "# </form>\n",
    "# \"\"\"\n",
    "\n",
    "try:\n",
    "    langfuse_ANSWER_USER_QUERY_SYSTEM_MESSAGE = langfuse_cl.get_prompt(\n",
    "        name=\"ANSWER_USER_QUERY_SYSTEM_MESSAGE\",\n",
    "        type=\"chat\",\n",
    "    )\n",
    "    \n",
    "    ANSWER_USER_QUERY_SYSTEM_MESSAGE = ChatPromptTemplate(\n",
    "        langfuse_ANSWER_USER_QUERY_SYSTEM_MESSAGE.get_langchain_prompt(),\n",
    "        metadata={\"langfuse_prompt\": langfuse_ANSWER_USER_QUERY_SYSTEM_MESSAGE}  # exactly like that for linked generation\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Unable to pull prompts from Langfuse server: ANSWER_USER_QUERY_SYSTEM_MESSAGE\")\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def answer_user_query(state: Ask_Ai_AgentState, config: RunnableConfig) -> Ask_Ai_AgentState:\n",
    "    \"\"\"\n",
    "    Generate a helpful answer to the user's question.\n",
    "\n",
    "    Behavior:\n",
    "    - Reads the user language and current form name from config.\n",
    "    - Builds a system message with instructions for tone, style,\n",
    "      and context (including the form being filled).\n",
    "    - Combines that with the recent conversation history.\n",
    "    - Sends everything to an LLM to create a reply.\n",
    "    - Returns the reply wrapped as an AIMessage.\n",
    "\n",
    "    Args:\n",
    "        state:  The current agent state (holds messages and context).\n",
    "        config: Runtime configuration with user-specific settings.\n",
    "\n",
    "    Returns:\n",
    "        Ask_Ai_AgentState update with the assistant's generated answer.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg(config)\n",
    "    user_language = cfg.get(\"user_language\", \"english\")\n",
    "    form_str = cfg.get(\"form_str\", \"—\")\n",
    "\n",
    "    # model = ChatGoogleGenerativeAI(\n",
    "    #     model=\"gemini-2.0-flash-lite\",\n",
    "    #     api_key=GEMINI_API_KEY,\n",
    "    #     temperature=0,\n",
    "    #     max_output_tokens=1000,  # <-- correct param name\n",
    "    # )\n",
    "\n",
    "    model      = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "    # system_msg = ANSWER_USER_QUERY_SYSTEM_MESSAGE.format(\n",
    "    #     form_str=form_str,\n",
    "    #     user_language=user_language,\n",
    "    # )\n",
    "    # print(user_language)\n",
    "    # print(form_str)\n",
    "    chain = ANSWER_USER_QUERY_SYSTEM_MESSAGE | model\n",
    "    response = await chain.ainvoke(\n",
    "        {\n",
    "            \"user_language\": user_language,\n",
    "            \"form_str\":      form_str,\n",
    "            \"chat_history\":  chat_history_to_text(trim_messages(state.messages)),\n",
    "        }\n",
    "    )\n",
    "    # print(chat_history_to_text(trim_messages(state.messages)))\n",
    "\n",
    "    # messages = [SystemMessage(content=system_msg)] + trim_messages(state.messages)\n",
    "    # response = await model.ainvoke(messages, config=config)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# BUILD THE GRAPH\n",
    "# -------------------------\n",
    "builder = StateGraph(Ask_Ai_AgentState)\n",
    "builder.add_node(\"query_relevance\", query_relevance)\n",
    "builder.add_node(\"answer_user_query\", answer_user_query)\n",
    "builder.add_node(\"cant_help\", cant_help)\n",
    "\n",
    "builder.set_entry_point(\"query_relevance\")\n",
    "builder.add_edge(\"cant_help\", END)\n",
    "builder.add_edge(\"answer_user_query\", END)\n",
    "builder.add_conditional_edges(source=\"query_relevance\", path=query_relevance_router, path_map=[\"cant_help\", \"answer_user_query\"])\n",
    "\n",
    "# # Compile with an in-memory checkpointer; resume by calling invoke() on the same thread_id\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Compile the graph with persistent checkpointer and in-memory store\n",
    "ask_ai_agent = builder.compile(checkpointer=checkpointer)# store=across_thread_memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3111d2c-5062-41d0-a972-5496407a0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  +-----------+                \n",
      "                  | __start__ |                \n",
      "                  +-----------+                \n",
      "                        *                      \n",
      "                        *                      \n",
      "                        *                      \n",
      "               +-----------------+             \n",
      "               | query_relevance |             \n",
      "               +-----------------+             \n",
      "                 ..            ..              \n",
      "               ..                ..            \n",
      "             ..                    ..          \n",
      "+-------------------+           +-----------+  \n",
      "| answer_user_query |           | cant_help |  \n",
      "+-------------------+           +-----------+  \n",
      "                 **            **              \n",
      "                   **        **                \n",
      "                     **    **                  \n",
      "                   +---------+                 \n",
      "                   | __end__ |                 \n",
      "                   +---------+                  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "# View\n",
    "try:\n",
    "    display(Image(ask_ai_agent.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    print(ask_ai_agent.get_graph().draw_ascii(), '\\n\\n')\n",
    "    # print(graph.get_graph().draw_mermaid())\n",
    "\n",
    "# GRAPH ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11c12f3a-ceb9-48ff-b583-b871d129dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "human: What should I fill-in in the full name field?\n",
      "ai: Hello! I see you are asking about the full name field. \n",
      "\n",
      "You should write your complete name as it appears on your official documents, like your passport or ID card. \n",
      "\n",
      "For example, if your name is \"John Michael Doe,\" write it exactly like that. \n",
      "\n",
      "If you need help with how to write your name, please tell me your name or ask!\n",
      "human: My name is Ans IMRAN?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What should I fill-in in the full name field?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I see you are asking about the full name field. \n",
      "\n",
      "You should write your complete name as it appears on your official documents, like your passport or ID card. \n",
      "\n",
      "For example, if your name is \"John Michael Doe,\" write it exactly like that. \n",
      "\n",
      "If you need help with how to write your name, please tell me your name or ask!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Ans IMRAN?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Ans Imran! Thank you for sharing your name. \n",
      "\n",
      "For the full name field, please write your name exactly as it appears on your official documents, like your passport or ID card. \n",
      "\n",
      "For example, if your name is \"Ans Imran,\" just write \"Ans Imran\" in the field. \n",
      "\n",
      "Would you like me to help you with anything else on the form?\n"
     ]
    }
   ],
   "source": [
    "# Example of an irrelevant query\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "import uuid\n",
    "\n",
    "user_language = 'english'\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"user_id\":'1',\n",
    "        \"thread_id\": '1', #str(uuid.uuid4()),\n",
    "        \"form_str\": form_str,\n",
    "        \"user_language\": user_language,\n",
    "    }\n",
    "}\n",
    "\n",
    "# 'что такое амбельдунг?'\n",
    "\n",
    "# What should I fill-in in the full name field.\n",
    "text=HumanMessage(content='My name is Ans IMRAN?')\n",
    "# Kick off (provide initial state once)\n",
    "output = await ask_ai_agent.ainvoke({\"messages\": [text]}, config=config)\n",
    "for msg in output['messages']:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea1c01-6f07-4f47-acad-c1780944f307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d63094-c56f-47f3-b9ca-f013b0c61ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4fc6f67-47d1-422f-b454-0345905f7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd446f51-d5ff-4c49-aeb4-b2f2e84906e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m text=HumanMessage(content=\u001b[33m'\u001b[39m\u001b[33mhi! what is the meaning of ambeldung?\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Kick off (provide initial state once)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m output = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mgraph\u001b[49m.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [text]}, config=config)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m output[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     23\u001b[39m     msg.pretty_print()\n",
      "\u001b[31mNameError\u001b[39m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "# Example of an relevant query\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "import uuid\n",
    "\n",
    "user_language = 'english'\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"user_id\":'Frank',\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"form_str\": form_str,\n",
    "        \"user_language\": user_language,\n",
    "    }\n",
    "}\n",
    "\n",
    "# 'что такое амбельдунг?'\n",
    "\n",
    "text=HumanMessage(content='hi! what is the meaning of ambeldung?')\n",
    "# Kick off (provide initial state once)\n",
    "output = await graph.ainvoke({\"messages\": [text]}, config=config)\n",
    "for msg in output['messages']:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d247f-b3ba-4a9b-930c-801f379e534d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080e894-c455-4f09-bb43-8933a6c7cd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b66f93-125f-4cd8-8847-a081dee152f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0a460-cfcd-4fd6-86d7-fb414a023196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df1cb7-1147-40ae-aab7-a12bbd3a91b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fb808-808f-463e-a6b7-412d638ef27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129aba9e-eb74-4004-a55b-ee8662499a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an relevant query\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "import uuid\n",
    "\n",
    "user_language = 'english'\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"user_id\":'Frank',\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"form_str\": form_str,\n",
    "        \"user_language\": user_language,\n",
    "    }\n",
    "}\n",
    "\n",
    "# 'что такое амбельдунг?'\n",
    "\n",
    "text=HumanMessage(content='hi! what is the meaning of ambeldung?')\n",
    "# Kick off (provide initial state once)\n",
    "output = await graph.ainvoke({\"messages\": [text]}, config=config)\n",
    "for msg in output['messages']:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1f982-b282-4594-9c13-2b4b0d680598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f02bbdf-6ff6-42c0-bdf3-76f121068d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f u bitch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if settings.LANGFUSE_TRACING == True:\n",
    "    print(\"f u bitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b6bca-682d-4682-ba1c-6b982398b551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2e72df3-175f-40fc-be95-726e726ba451",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal here. Maybe you meant '==' instead of '='? (2712480297.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mANSWER_USER_QUERY_SYSTEM_MESSAGE.invoke(input={'form_str'='blabla ba', 'user_language'='njiw'})\u001b[39m\n                                                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m cannot assign to literal here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "ANSWER_USER_QUERY_SYSTEM_MESSAGE.invoke("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d45ee-c7d6-423c-b2dd-675a7a21f0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a41f9b8-c015-4e27-8835-7ee9d2146341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f88c8582-d9cd-4f28-a0d1-f58d28d7888b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: Your name is `ask ai`. You are a kind, patient assistant for refugees using the wcr.is website.\\n\\nThe site has multiple forms.\\nThe user chooses the form that matches their current need.\\nThey fill out the form in another tab, not in this chat.\\nWhile completing it, they may ask you about words, legal terms, or any confusing part.\\nYour job is to guide them so they can finish the form correctly.\\n\\nHow to respond:\\n- The user has selected <user_language> njiw </user_language> language. So your response should be in <user_language> njiw </user_language> language.\\n- Be very polite and supportive.\\n- Use short sentences.\\n- Use simple, everyday language.\\n- Explain step by step.\\n- Focus on the exact question the user is stuck on.\\n- Give short examples when helpful.\\n- If you need details, ask one clear question at a time.\\n- Adjust your tone and explanation style to fit the person you’re talking to.\\n    - If the person is not well-educated, avoid technical terms. Use simple words and short sentences.\\n    - If the person seems to be in trauma, respond with care, love, and support. Focus on uplifting their spirit.\\n    - Infer the person’s eloquence based on how their question is written. \\n        - If the question is unclear or sloppy: use simpler language, slow down, and give more (and more concrete) examples.\\n        - If the question is eloquent and precise: be succinct and get straight to the point, with minimal examples.\\n\\n- Name of the form is given below. Always tell the user that you are currently helping with this form.\\n\\nCurrent form:\\n<form>\\nblabla ba\\n</form>\\n\\nHuman: Next, you'll see human message.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWER_USER_QUERY_SYSTEM_MESSAGE.format(form_str='blabla ba', user_language='njiw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6a077-0608-46f4-a895-02b7c77cca19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
